\chapter{Aufwand}
% Aufwand -> Was ist das
% Beispiel Aufwand TM
% Diskussion Modell TM (Einfachheit vs Realitätsnähe)
% Swap
Das Thema dieses Kapitels lässt sich mit einer Frage zusammenfassen:
Wie bemessen wir den Aufwand,
den es braucht ein Problem durch einen Algorithmus zu lösen?
In \autoref{einleitung} haben wir formale Sprachen als Repräsentation von Problemen eingeführt,
in \autoref{reg} haben wir gelernt, was ein Algorithmus ist und
in \autoref{turing} wurde eine Möglichkeit eingeführt,
alle bekannten Algorithmen zu implementieren:
die Turingmaschine.
Diesen Formalismus wollen wir in diesem Kapitel nutzen,
um genau zu spezifizieren,
was Aufwand bedeutet.

\section{Warum nicht einfach Messen?}\label{messenVsBeweisen}

Bevor wir uns dem Thema theoretisch nähern,
wollen wir noch eine ganz praktische Erwägung durchdenken:
Warum nicht einfach den Aufwand messen,
anstatt ihn über die Eigenschaften einer Turinmaschinen zu quantifizieren?
Die Idee hierbei:
Implementiere den Algorithmus in einer beliebigen Sprache
und messe die Zeit,
wie lange die Implementierung läuft.
Hierbei ergeben sich einige Schwierigkeiten:
\begin{itemize}
  \item Auf welchem Input soll die Implementierung laufen?
      Die Menge der möglichen Inputs vieler Algorithmen ist unendlich,
      daher kann man nur Stichproben aus den möglichen Inputs nehmen
        und muss sich der Methodik der Statistik bedienen,
        um allgemeine Aussagen zu rechtfertigen
    \item Das „Rauschen“ bei Messungen muss berücksichtigt werden
        (die folgende Aufzählung ist wahrscheinlich nicht vollständig):
      \begin{itemize}
          \item Genutzte Hardware
          \item Genutztes Betriebssystem
          \item Spezifische Versionen (z.B. Compiler, Browser, OS)
          \item Lastsituation auf der Maschine
          \item Virtualisierung
          \item Netz
      \end{itemize}
      Dies macht den Vergleich von Messergebnissen extrem schwierig,
        wenn nicht sogar in vielen Fällen praktisch wertlos.
\end{itemize}

Es ist also offensichtlich,
dass man nicht ``einfach'' messen kann.
Dennoch hat die empirische Messung auch in der Informatik ihren Platz.
Wir werden darauf noch einmal am Ende des Kapitels zurückkommen.

\section{Effizienz in Zeit (und Raum)}

Was meinen wir, wenn wir von Aufwand oder Effizienz einer Berechnung sprechen?
Meist wird als erstes die \emph{Zeit} genannt,
die es braucht,
damit eine Berechnung ein Ergebnis liefert.
Es wäre ebenso möglich,
den \emph{Speicherplatz}\footnote{
    Im Englischen sprechen wir von ``space'', daher die Überschrift des Abschnitts.}
als Aufwandsdimension zu verstehen,
den eine Implementierung benötigt,
um den Input,
eventuelle Zwischenergebnisse
und den Output zu speichern.
Beides, Zeit und Speicherplatz sind valide Größen,
anhand derer wir Aufwand oder Effizienz bemessen können.
Wir werden uns in diesem Skript auf Zeit-Effizienz konzentireren,
weswegen wir bei Aufwand beziehungsweise Effizienz immer von
zeitlichem Aufwand beziehungsweise zeitlicher Effizienz sprechen,
wenn wir Speicherplatz nicht explizit mitnennen.
Allerdings kann einiges auf Raum-Effizienz übertragen werden,
das wir in diesem Kapitel entwickeln.

Wir wollen über diese drei folgenden Schritte zu einem Verständnis von Aufwand kommen:
\begin{itemize}
    \item Aufwand für einen Lauf einer spezifischen Turingmaschine auf einem spezifischen Wort.
    \item Abschätzung für die Länge von Läufen einer spezifischen Turingmaschine
        auf allen Worten einer Sprache.
    \item Schranken für alle Turingmaschinen, die eine spezifische Sprache erkennen.
\end{itemize}

Die folgenden Abschnitte hangeln sich an diesen Schritten entlang.

\subsection{Aufwand eines spezifischen Laufs}
Am Anfang unserer Überlegung haben wir diese zwei Komponenten:
\begin{itemize}
    \item Die konkrete Problemstellung, gegeben als Frage \emph{Wort $w \in L$}? 
    \item Den konkreten Algorithmus,
        implementiert als \emph{Turingmaschine $tm \in TM$}.\footnote{
            $TM$ bezeichnet die Menge aller Turingmaschinen.}
\end{itemize}
Gesucht ist eine Funktion $\tau: L \times TM \rightarrow \mathbb{N}$,
die für ein Wort $w \in L$ auf einer bestimmten Turingmaschine $tm \in TM$
den zeitlichen Aufwand in einer natürlichen Zahl ausdrückt.

Glücklicherweise haben wir in \autoref{turing} bereits ein Konzept eingeführt,
dass wir hierfür nutzen können:
Die Länge des Laufes von $w$ auf $tm$:
$\tau: \Sigma^* \times TM \rightarrow \mathbb{N}$ ist die Funktion,
die für ein Wort $w \in \Sigma^*$ den Zeitaufwand auf einer Turingmaschine TM angibt.
Wir legen fest: $\tau(w,tm) = |l_{w,tm}|$.
Für ein Wort $w \in L$ ergibt sich eine Folge von Schnappschüssen,
dessen Länge wir als zeitlichen Aufwand definieren.


\subsubsection{Beispiel: Drehe 10 um}

Wir wollen $\tau$ an einem Beispiel erläutern.
Sei REVERSE das folgende Problem:
\begin{itemize}
    \item \textbf{Gegeben}: Ein beliebig langes Wort $w \in \Sigma^*$ mit $\Sigma = \{0,1\}$.
    \item \textbf{Gesucht}: Das Wort rückwärts.
\end{itemize}

Wäre also $w = 10$, dann wäre $w' = 01$ gesucht und damit $1001 \in$ REVERSE.
D.h. REVERSE ist eine formale Sprache,
welche die ``Rückwärts-Funktion`` kodiert:
REVERSE = $\{00, 11, 0000, 0110, 1001, 1111, \ldots\}$
\autoref{fig:tmreverse} zeigt eine Turingmaschine $tm$, die REVERSE erkennt.

\newpage

\begin{figure}[H] % ’ht’ tells LaTeX to place the figure ’here’ or at the top of the page
\centering % centers the figure
\begin{tikzpicture}
    %Initial part
    \node[state] (zLI) {$z_{LI}$};
    \node[state, left of=zLI] (zI12) {$z_{I12}$};
    \node[state, above of=zLI] (zI02) {$z_{I02}$};
    \node[state, above of=zI12] (zI11) {$z_{I11}$};
    \node[state, above of=zI02] (zI01) {$z_{I01}$};
	\node[state, accepting, initial, left of=zI01] (zI) {$z_I$};

    %Loop part
    \node[state, right of=zLI] (zL01) {$z_{L01}$};
    \node[state, above right of=zL01] (zLC) {$z_{LC}$};


    \node[state, below of=zL01] (zL02) {$z_{L02}$};

    \node[state, below right of=zLC] (zL11) {$z_{L11}$};
    \node[state, below of=zL11] (zL12) {$z_{L12}$};

    \node[state, below left of=zL12] (zL3) {$z_{L3}$};

    %Finish part

    \node[state, above left of=zLC] (zF0) {$z_{F0}$};
    \node[state, above right of=zF0] (zF1) {$z_{F1}$};
    \node[state, accepting, right of=zF1] (zF2) {$z_{F2}$};

	\draw

        %Initial part
        (zI) edge[above] node{0,0,L} (zI01)
        (zI01) edge[right] node{$\square$,$\square$,L} (zI02)
        (zI02) edge[left] node{$\square$,0,R} (zLI)

        (zI) edge[above right] node{1,1,L} (zI11)
        (zI11) edge[left, right] node{$\square$,$\square$,L} (zI12)
        (zI12) edge[above] node{$\square$,1,R} (zLI)

        %Loop part
        (zLC) edge[left] node{0,0,L} (zL01)
        (zLC) edge[above right] node{1,1,L} (zL11)
        (zLC) edge[right] node{$\square$,$\square$,L} (zF0)

        (zL01) edge[loop right] node{$\square$,$\square$,L} (zL01)
        (zL01) edge[left]
            node[text width=1cm, align=center]{0,0,L\\1,1,L} 
            (zL02)

        (zL02) edge[loop right] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L} 
            (zL02)
        (zL02) edge[right] node{$\square$,0,R} (zL3)

        (zL11) edge[loop right] node{$\square$,$\square$,L} (zL11)
        (zL11) edge[left]
            node[text width=1cm, align=center]{0,0,L\\1,1,L} 
            (zL12)

        (zL12) edge[loop right] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L} 
            (zL12)
        (zL12) edge[right] node{$\square$,1,R} (zL3)


        (zL3) edge[loop below] 
            node[text width=1cm, align=center]{0,0,R\\1,1,R} 
            (zL3)
        (zL3) edge[bend left, left] node{$\square$,$\square$,R}(zLI)

        (zLI) edge[in=210, out=240, looseness=8, below] node{$\square$,$\square$,R} (zLI)
        (zLI) edge[bend left, above left] 
            node[text width=1cm, align=center]
            {0,$\square$,R\\1,$\square$,R} 
            (zLC) 

        %Finish part
        (zF0) edge[loop above] node{$\square$,$\square$,L} (zF0)
        (zF0) edge[below right] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L} 
            (zF1)
        (zF1) edge[loop above] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L} 
            (zF1)
        (zF1) edge[above] node{$\square$,$\square$,R} (zF2)
    ;
\end{tikzpicture}
\caption{Turingmaschine, die $REVERSE$ akzeptiert \\
(siehe auch: \url{https://turingmachinesimulator.com/shared/xquktlulex})}
\label{fig:tmreverse}
\end{figure}

\newpage
Dies ist der Lauf $l_{10, tm}$:


\setcounter{arraycounter}{-1}
\begin{center}
$
\arraycolsep=15.0pt
    \begin{array}{>{\stepcounter{arraycounter}\thearraycounter\mspace{20mu}}llrlrl}
[   & [z_I,     & \sq,              & 1,    & 0]                & , \\
    & [z_{I11}, & \sq,              & \sq,  & 10]               & , \\
    & [z_{I12}, & \sq,              & \sq,  & \sq10]            & , \\
    & [z_{LI},  & \sq1,             & \sq,  & 10]               & , \\
    & [z_{LI},  & \sq1\sq,          & 1,    & 0]                & , \\
    & [z_{LC},  & \sq1\R{2}{\sq},   & 0,    & \sq]              & , \\
    & [z_{L01}, & \sq1\sq,          & \sq,  & 0\sq]             & , \\
    & [z_{L01}, & \sq1,             & \sq,  & \sq0\sq]          & , \\
    & [z_{L01}, & \sq,              & 1,    & \R{2}{\sq}0\sq]   & , \\
    & [z_{L02}, & \sq,              & \sq,  & 1\R{2}{\sq}0\sq]  & , \\
    & [z_{L3},  & \sq0,             & 1,    & \R{2}{\sq}0\sq]   & , \\
    & [z_{L3},  & \sq01             & \sq,  & \sq0\sq]          & , \\
    & [z_{LI},  & \sq01\sq,         & \sq,  & 0\sq]             & , \\
    & [z_{LI},  & \sq01\R{2}{\sq},  & 0,    & \sq]              & , \\
    & [z_{LC},  & \sq01\R{3}{\sq},  & \sq,  & \sq]              & , \\
    & [z_{LF0}, & \sq01\R{2}{\sq},  & \sq,  & \R{2}{\sq}]       & , \\
    & [z_{LF0}, & \sq01\sq,         & \sq,  & \R{3}{\sq}]       & , \\
    & [z_{LF0}, & \sq01,            & \sq,  & \R{4}{\sq}]       & , \\
    & [z_{LF0}, & \sq0,             & 1,    & \R{5}{\sq}]       & , \\
    & [z_{LF1}, & \sq,              & 0,    & 1\R{5}{\sq}]      & , \\
    & [z_{LF1}, & \sq,              & \sq,  & 01\R{5}{\sq}]     & , \\
    & [z_{LF2}, & \R{2}{\sq},       & 0,    & 1\R{5}{\sq}]      & ] \\
\end{array}
$
\end{center}

In diesem Fall hat $\tau$ also den folgenden Wert:
\[
\tau(10,tm) = 21
\]

\subsection{Aufwandsabschätzung für eine Implementierung}

Bisher haben wir aber nur über den Aufwand gesprochen,
den ein spezfischer Lauf auf einem Wort verursacht,
nicht aber wie sich der Aufwand für das Problem generell verhält,
gegeben eine Implementierung.
Wir betrachten daher also:
\begin{itemize}
    \item Die konkrete Implementierung eines Algorithmus,
        gegeben als \emph{Turingmaschine $tm \in TM$}.
\end{itemize}

Wie können wir nun auf den Ergebnissen aus dem vorherigen Abschnitt aufbauen?
Eine Sprache kann unendlich viele Worte enthalten,
d.h. Lösungen, die darauf beruhen,
dass es ein Minimum oder Maximum von $\tau$ für ein Wort $w \in L$ gibt,
sind nicht zielführend.

Betrachten wir Probleme als Funktionen (siehe \autoref{subsec:problemeAlsFormaleSprachen}),
können wir aber die \emph{Größe} des Inputs in Relation zum Aufwand setzen.
Die Intuition dabei:
Je größer der Input der Funktion (je größer also die Zahl,
je länger die Input-Liste, etc.)
desto größer der Aufwand.
Um zu beschreiben,
wie groß der Aufwand ist,
ein Problem auf einer Turingmaschine zu lösen,
suchen wir eine Funktion,
die die Inputgröße und die Turingmaschine auf die Anzahl an Schritten abbildet.
Übertragen auf den Kontext der formalen Sprachen
können wir anstatt dem Input die Wortlänge betrachten:
Beschreibe, wie sich das Laufzeitverhalten einer Turingmaschine 
bei wachsender Wortlänge verhält.
%TODO Grafik

Gesucht ist also die folgende Funktion:
$t: \mathbb{N} \times TM \rightarrow \mathbb{N}$,
also die Abbildung einer Wortlänge und einer Turingmaschine
auf die Anzahl der Schritte für ein Wort dieser Länge.
Da mehrere Worte die gleiche Länge haben können,
müssen wir die Möglichkeiten diskutieren,
wie wir in diesem Falle zu einem eindeutigen Wert kommen können:
\begin{itemize}
    \item \textbf{Best Case}: Wir wählen das Wort der Länge aus,
        für das der Algorithmus den kürzesten Lauf hat,
        also die geringste Zeit benötigt.
    \item \textbf{Average Case}: Wir nutzen statistische Methoden,
        um die wahrscheinliche Länge eines Laufs zu quantifizieren.
        Wir betrachten also zum Beispiel den Erwartungswert von $\tau$,\footnote{
            In diesem Fall bildet $tm$ auf $\mathbb{Q}$ ab und nicht mehr auf $\mathbb{N}$.}
        wenn wir per Zufall ein Wort aus L der gegebenen Länge auswählen.\footnote{
            Der Modus (entspricht dem Median in einer endlichen Stichprobe) wäre eine Alternative.
        Mit der Standardabweichung (Streuungsmaß) oder einer Kombination mehrerer Maße,
        verbessert sich die Aussagekraft,
        was aber die einfache Vergleichbarkeit von Algorithmen wiederum erschwert.}

    \item \textbf{Worst Case}: Wir wählen das Wort aus,
        für das der Algorithmus den längsten Lauf hat,
        also die meiste Zeit benötigt.
\end{itemize} 

Da der Best Case meist wenig Aussagekraft über die Güte des Algorithmus besitzt,
wird er selten als Maß für den Aufwand eines Problems genutzt.
Am aussagekräftigsten ist der Average Case,
aber um ihn formal sauber anzuwenden braucht es
entsprechendes statistisches Werkzeug.\footnote{
    Für interessierte Leser:innen sei \cite{knuth1}, 96ff bzw. 1.2.10 empfohlen,
    hier spielt Knuth die probabilistische Analyse des Euklidischen Algorithmus durch.} 
Ganz pragmatisch konzentrieren wir uns auf den Worst Case.


$t_{tm}$ können wir mit diesen Überlegungen also definieren als:
\[
t_{tm}(n) = max({\tau(w, tm)| |w| = n})
\]
$t_{tm}$ gibt also die jeweilige Worst Case Laufzeit für ein Wort der Länge $n$ an.
Dies erlaubt es uns auch über unendlich große formale Sprachen Aussagen zu treffen,
indem wir angeben,
wie sich der Aufwand bei steigender Inputgröße,
das bedeutet bei steigender Wortlänge entwickelt.

%TODO Beispiel

\subsection{Untere und obere Schranken für den Aufwand}
Mit $t_{tm}$ und dem Worst Case-Wert können wir Aussagen über den Aufwand treffen,
den ein bestimmter Algorithmus für ein bestimmtes Problem verursacht.
Wir treffen allerdings keine Aussagen darüber,
wie viel Aufwand das Problem \emph{an sich} erzeugt.
Dazu müssten wir Aussagen über alle prinzipiell \emph{möglichen} Algorithmen,
also Turingmaschinen treffen,
die das Problem lösen:
Den Aufwand eines Problems würden wir dann mit dem effizientesten Algorithmus gleichsetzen.
Oftmals ist der Nachweis sehr schwer,
ob es (k)einen effizienteren Algorithmus
für ein Problem gibt.
Den aktuellen Stand der Forschung erlernt man typischer Weise in Vorlesungen über
Algorithmen und Datenstrukturen.

%Ein Beispiel hierfür ergibt sich aus $U\textsubscript{ARTICLESORT}$.
%Fassen wir dieses Problem informell so auf $I\textsubscript{ARTICLESORT}$:
%\begin{itemize}
%    \item Gegeben ein Tupel von Zahlen
%    \item Gesucht: die Permutatio des Tupels, die absteigend sortiert ist
%\end{itemize}
%So gibt es viele Algorithmen, die dieses Problem lösen.
%Für vergleichbasierte Sortieralgorithmen lässt sich eine untere Schranke finden. 

\section{Landau und Big-O: Wachstum}

$t_{tm}$ ist eine Möglichkeit,
die Aufwandsentwicklung für steigende Inputgrößen formal zu spezifizieren.
Für die meisten Fälle ist $t_{tm}$ aber zu feingranular:
Wir interessieren uns beispielsweise nur dafür,
ob sich das Laufzeitverhalten sinnvoll beschränken lässt,
d.h. ob es eine asymptotische obere oder untere Schranke für den Aufwand gibt.

Dies wird typischerweise mit der Landau-Notation angeben.
Wir definieren eine Menge von Funktionen in Abhängigkeit einer oberen Schranke
und lassen dabei Faktoren außen vor,
die für die Wachstumsdynamik unwesentlich sind:

\[
O(g(n)) = \{f|\exists c \exists n_0 \forall n (n \geq n_0 \rightarrow f(n) \leq c \cdot g(n))\}
\]

% TODO: Ergänze andere Klassen (o, $\theta$ usw).

\section{Simulationen}

Warum nutzen wir (in diesem Skript) Turingmaschinen zur Aufwandsquantifikation?
Wir haben die Church-Turing-These eingeführt und operieren auf der Annahme,
dass sich jedes (berechenbare) Problem durch eine Turingmaschine lösen lässt.

Andere Formalismen lassen sich auf einer Turingmaschine simulieren und
der Aufwand der Simulation lässt sich quantifizieren,
d.h. wir können die ``Beschleunigigung'' durch andere Formalismen
(z.B. solche, die einen realistisches Speicherkonzept haben)
genau beziffern.

Hier Diskussion Sortierungsalgorithmen.
\begin{itemize}
    \item Relativ zur Implementierungssprache (Mehrbandturingmaschinen, Registermaschinen)
    \item Relativ zur Datenrepräsentation (Größe des Alphabets, Art der Datenstrukturen)
\end{itemize}

\section{Warum eine empirische Messung dennoch sinnvoll ist}
Die Idee den Aufwand eines Algorithmus über das ``Laufzeitverhalten'' einer Turingmaschine zu bestimmen,
umgeht die Herausforderungen empirischer Messungen, die wir am Anfang des Kapitels skizziert haben.

Eine Messung ist dennoch ein valides (wissenschaftliches) Instrument,
um Aussagen über Algorithmen und deren Implementierungen zu erhalten.
Der theoretische Ansatz dieses Kapitels basiert auf einigen Annahmen,
die selbst nicht unproblematisch sind:
\begin{itemize}
  \item Operationen haben auf einer Turingmaschine identischen Aufwand.
    Dies ist auf ``echter'' Hardware zumeist anders.
    Die Frage ist daher, welche Aussagekraft die Analyse eines Algorithmus auf einer Turingmaschine für realistische Szenarien hat. 
  \item Daten und Zwischenergebnisse nutzen identischen Speicherplatz.
  \item Der Input einer Turingmaschine kann unendlich wachsen,
      In der Reailität ist dieser Platz begrenzt (z.B. der verfügbare Hauptspeicher).
  %\item Ist jeder Input gleich wahrscheinlich?
\end{itemize}

\chapter{Aufwand}


Das Thema dieses Kapitels lässt sich mit einer Frage zusammenfassen:
Wie bemessen wir den Aufwand,
den es braucht ein Problem durch einen Algorithmus zu lösen?
In \autoref{einleitung} haben wir formale Sprachen als Repräsentation von Problemen eingeführt,
in \autoref{reg} haben wir gelernt, was ein Algorithmus ist und
in \autoref{turing} wurde eine Möglichkeit eingeführt,
alle bekannten Algorithmen zu implementieren:
die Turingmaschine.
Diesen Formalismus wollen wir in diesem Kapitel nutzen,
um genau zu spezifizieren,
was Aufwand bedeutet.

\section{Warum nicht einfach Messen?}\label{messenVsBeweisen}

Bevor wir uns dem Thema theoretisch nähern,
wollen wir noch eine ganz praktische Erwägung durchdenken:
Warum nicht einfach den Aufwand messen,
anstatt ihn über die Eigenschaften einer Turinmaschinen zu quantifizieren?
Die Idee hierbei:
Implementiere den Algorithmus in einer beliebigen Programmiersprache
und messe die Laufzeit.
Hierbei ergeben sich einige Schwierigkeiten:
\begin{itemize}
  \item Auf welchem Input soll die Implementierung laufen?
      Wir können annehmen, dass die Menge der möglichen Inputs des Algorithmus in Frage unendlich ist.
      Da wir deshalb mit Stichproben aus diesen möglichen Inputs arbeiten müssen,
      sind wir gezwungen die Methoden der Statistik anzuwenden,
        um allgemeine Aussagen zu rechtfertigen.
    \item Das „Rauschen“ bei Messungen muss berücksichtigt werden:
        Die folgenden ``Störfaktoren'' machen
        die Vergleichbarkeit von Messergebnissen zu einer
        großen Herausforderung (die Liste ist wahrscheinlich nicht vollständig):
      \begin{itemize}
          \item Genutzte Hardware
          \item Genutztes Betriebssystem
          \item Spezifische Versionen (z.B. Compiler, Browser, OS)
          \item Lastsituation auf der Maschine
          \item Virtualisierung
          \item Netzauslastung
          \item Temperatur
          \item Messmethode
      \end{itemize}
\end{itemize}

Es ist also offensichtlich,
dass man nicht ``einfach'' messen kann.


\subsection{Warum eine empirische Messung dennoch sinnvoll ist}
Eine Messung ist dennoch ein valides (wissenschaftliches) Instrument,
um Aussagen über Algorithmen und deren Implementierungen zu erhalten.
Der theoretische Ansatz dieses Kapitels basiert auf einigen Annahmen,
die selbst nicht unproblematisch sind:
\begin{itemize}
  \item Operationen haben auf einer Turingmaschine identischen Aufwand.
    Dies ist auf ``echter'' Hardware zumeist anders.
    Die Frage ist daher, welche Aussagekraft die Analyse eines Algorithmus auf einer Turingmaschine für realistische Szenarien hat.
  %\item Daten und Zwischenergebnisse nutzen identischen Speicherplatz.
  \item Der Input einer Turingmaschine kann unendlich wachsen,
      In der Reailität ist dieser Platz begrenzt (z.B. der verfügbare Hauptspeicher).
  %\item Ist jeder Input gleich wahrscheinlich?
\end{itemize}

Aufwandsabschätzungen konkreter Algorithmen werden aus diesen Gründen in der Praxis \emph{nicht} mit Turingmaschinen vorgenommen.\footnote{%
    Vorlesungen zum Themen ``Algorithmen und Datenstrukturen'' führen in die Methodik ein,
    wie Abschätzungen in der Praxis durchgeführt werden.}
Die Überlegeungen über Aufwand, die wir im aktuellen Kapitel einführen,
sind für eine andere Größenordnung gedacht,
wie wir im Kapitel \autoref{complex} sehen werden.

\section{Zeit-Aufwand}

Was meinen wir, wenn wir von Aufwand oder Effizienz einer Berechnung sprechen?
Meist wird als erstes die \emph{Zeit} genannt,
die es braucht,
damit eine Berechnung ein Ergebnis liefert.

Es wäre ebenso möglich,
den \emph{Speicherplatz} als Aufwandsdimension zu verstehen,
den eine Implementierung benötigt,
um den Input,
eventuelle Zwischenergebnisse
und den Output zu speichern.
Beides, Zeit und Speicherplatz sind valide Größen,
anhand derer wir Aufwand oder Effizienz bemessen können.
Wir werden uns in diesem Skript auf Zeit-Effizienz konzentrieren,
weswegen wir bei Aufwand beziehungsweise Effizienz immer von
zeitlichem Aufwand beziehungsweise zeitlicher Effizienz sprechen.
Allerdings kann einiges auf Speicherplatz-Effizienz übertragen werden,
das wir in diesem Kapitel entwickeln.
Wir wollen über diese drei folgenden Schritte zu einem Verständnis von Aufwand kommen:
\begin{enumerate}
    \item Aufwand für einen einzelnen Lauf einer spezifischen Turingmaschine
    \item Aufwand für alle Läufe auf einer spezifischen Turingmaschine
    \item Schranken für alle Läufe auf allen Turingmaschinen,
        die eine spezifische Sprache erkennen, also ein spezifisches Problem lösen.
\end{enumerate}

Die folgenden Unterkapitel folgen diesen Schritten,
indem zuerst theoretisch die Aufwandsquantifikation erschlossen wird
und diese dann an einem Beispiel praktische durchgespielt.

\subsection{Aufwandsquantifizierung für einen Lauf}
Am Anfang unserer Überlegung haben wir diese zwei Komponenten:
\begin{itemize}
    \item Ein \emph{Wort} $w_i \in \Sigma^*$
    \item Einen Algorithmus,
        implementiert als \emph{Turingmaschine $tm \in TM$}.\footnote{%
            $TM$ bezeichnet die Menge aller Turingmaschinen.}
\end{itemize}
Gesucht ist eine Funktion $\tau: TM \times \Sigma^* \rightarrow \mathbb{N}$,
die für ein Wort $w \in L$ auf einer bestimmten Turingmaschine $tm \in TM$
den zeitlichen Aufwand in einer natürlichen Zahl ausdrückt.

Glücklicherweise haben wir in \autoref{turing} bereits ein Konzept eingeführt,
welches wir hierfür nutzen können:
Die Länge des akzeptiernden Laufes $S_a(tm, w)$.

$\tau: TM \times \Sigma^* \rightarrow \mathbb{N}$ ist die Funktion,
die für ein Wort $w_i \in \Sigma^*$ den Zeitaufwand auf einer Turingmaschine $tm$ angibt.
Wir legen fest:
\[
    \tau(tm, w_i) = 
        \begin{cases}
            |S_a(tm,w_i)| - 1,   & \text{wenn } w_{i}w_o \in L(TM) \text{\ mit } w_o = Output(tm, w_i)\\
            \text{undefiniert}  & \text{sonst}
        \end{cases}
\]
Für ein Wort $w_i \in \Sigma^*$ zählen wir also die Schritte im akzteptierenden Lauf.


\subsubsection{Beispiel: Drehe 100 um}

Wir wollen $\tau$ an einem Beispiel erläutern.
Sei REVERSE das folgende Problem:
\begin{itemize}
    \item \textbf{Gegeben}: Ein beliebig langes Binärwort $w_i \in \Sigma^*$ mit $\Sigma = \{0,1\}$.
    \item \textbf{Gesucht}: Das Wort rückwärts.
\end{itemize}


\noindent
Nehmen wir also beispielsweise an, dass
\[ 
    w_i = 100 
\]
dann wäre 
\[
    w_o = 001
\]
gesucht und damit
\[
    w = 100001 = w_{i}w_o \in REVERSE.
\]

\noindent
REVERSE kodiert also formale Sprache also die ``Rückwärts-Funktion'':
\[
    REVERSE = \{00, 11, 0000, 0110, 1001, 1111, \ldots\}
\]

\noindent
\autoref{fig:tmreverse} zeigt eine Turingmaschine $tm_{REVERSE}$, die REVERSE erkennt.
\\

\noindent
Den konkreten Lauf auf $w_i = 100$ wollen wir nutzen,
um zu zeigen, wie sich der Wert von $\tau(tm_{REVERSE}, w_i)$ feststellen lässt.
Die folgende Tabelle zeigt den den akzeptierenden Lauf $S_a(tm_{REVERSE}, 100)$:

\setcounter{arraycounter}{-1}
\begin{center}
$
\arraycolsep=15.0pt
    \begin{array}{>{\stepcounter{arraycounter}\thearraycounter\mspace{20mu}}llrlrl}
[   & [I,   & \sq,          & 1,    & 00]               & , \\
    & [C,   & \sq1,         & 0,    & 0]                & , \\
    & [LS,  & \sq10,        & 0,    & \sq]              & , \\
    & [L0,  & \sq1,         & 0,    & 0\sq]             & , \\
    & [0L1, & \sq,          & 1,    & \sq0\sq]          & , \\
    & [0L2, & \sq,          & \sq,  & 1\sq0\sq]         & , \\
    & [L3,  & \sq0,         & 1,    & \sq0\sq]          & , \\
    & [L4,  & \sq01,        & \sq,  & 0\sq]             & , \\
    & [L4,  & \sq01\sq,     & 0,    & \sq]              & , \\
    & [LS,  & \sq01\sq0,    & \sq,  & \sq]              & , \\
    & [F0,  & \sq01\sq,     & 0,    & \sq\sq]           & , \\
    & [0F1, & \sq01,        & \sq,  & \sq\sq\sq]        & , \\
    & [0F1, & \sq0,         & 1,    & \sq\sq\sq\sq]     & , \\
    & [0F2, & \sq,          & 0,    & 1\sq\sq\sq\sq]    & , \\
    & [0F2, & \sq,          & \sq,  & 01\sq\sq\sq\sq]   & , \\
    & [F3, & \sq,           & 0,    & 01\sq\sq\sq\sq]   & ] \\
\end{array}
$
\end{center}
\noindent
Da $|S_a(tm_{REVERSE},100)| = 16$ gilt: $tau(tm_{REVERSE},100) = 15$
\newpage

\begin{figure}[H] % ’ht’ tells LaTeX to place the figure ’here’ or at the top of the page

\centering % centers the figure
\begin{tikzpicture}
    %Initial part
    \node[state, initial] (I) {I};
    \node[state, below of=I] (C) {C};
    %Loop part
    \node[state, below of=C] (LS) {LS};
    \node[state, below of=LS] (L0) {L0};
    \node[state, below left of=L0] (0L1) {0L1};
    \node[state, below right of=L0] (1L1) {1L1};
    \node[state, below of=0L1] (0L2) {0L2};
    \node[state, below of=1L1] (1L2) {1L2};
    \node[state, below right of=0L2] (L3) {L3};
    \node[state, below right of=1L2] (L4) {L4};

    %Finish part
    \node[state, right of=LS] (F0) {F0};
    \node[state, above right of=F0] (0F1) {0F1};
    \node[state, right of=0F1] (0F2) {0F2};
    \node[state, below right of=F0] (1F1) {1F1};
    \node[state, right of=1F1] (1F2) {1F2};
    \node[state, accepting, below right of=0F2] (F3) {F3};
	\draw

%        %Initial part
         (I) edge[left] 
            node[text width=1cm, align=center]{0,0,R\\1,1,R}
             (C)
         (C) edge[bend left=90, above] node{$\square$,$\square$,L} (F3)
         (C) edge[left] 
             node[text width=1cm, align=center]{0,0,R\\1,1,R}
             (LS)
%        %Loop part
         (LS) edge[above] node{$\square$,$\square$,L} (F0)
         (LS) edge[left] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (L0)
         (L0) edge[above right] node{1,$\square$,L} (1L1)
         (L0) edge[above left] node{0,$\square$,L} (0L1)

         (0L1) edge[loop left] 
            node{$\square$,$\square$,L}
            (0L1)
         (0L1) edge[left] 
             node[text width=1cm, align=center]{0,0,L\\1,1,L}
             (0L2)
         (0L2) edge[loop left] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (0L2)
         (0L2) edge[left] node{$\square$,0,R} (L3)

         (1L1) edge[loop left] 
            node{$\square$,$\square$,L}
            (1L1)
         (1L1) edge[left] 
             node[text width=1cm, align=center]{0,0,L\\1,1,L}
             (1L2)
         (1L2) edge[loop left] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (1L2)
         (1L2) edge[right] node{$\square$,1,R} (L3)

         (L3) edge[loop below] 
            node[text width=1cm, align=center]{0,0,R\\1,1,R}
             (L3)
         (L3) edge[above] node{$\square$,$\square$,R} (L4)

         (L4) edge[loop below] 
            node{$\square$,$\square$,R}
         (L4)
         (L4) edge[bend right=20, right] 
            node[text width=1cm, align=center]{0,0,R\\1,1,R}
         (LS)
%        %Finish part
         (F0) edge[above left] node{0,$\square$,L} (0F1)
         (0F1) edge[loop below] 
            node{$\square$,$\square$,L}
            (0F1)
         (0F1) edge[above] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (0F2)
         (0F2) edge[loop below] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (0F2)
         (0F2) edge[above right] node{$\square$,0,-} (F3)

         (F0) edge[below left] node{1,$\square$,L} (1F1)
         (1F1) edge[loop below] 
            node{$\square$,$\square$,L}
            (1F1)
         (1F1) edge[above] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (1F2)
         (1F2) edge[loop below] 
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (1F2)
         (1F2) edge[below right] node{$\square$,1,-} (F3)

    ;
\end{tikzpicture}
\caption{$tm_{REVERSE}$}%
\label{fig:tmreverse}
\end{figure}


\subsection{Aufwandsquantifizierung für eine Implementierung}

Bisher haben wir nur über den Aufwand gesprochen,
den ein spezifischer Lauf auf einem Wort verursacht,
nicht aber,
wie sich der Aufwand für eine komplette Implementierung quantifizieren lässt.
Wir betrachten daher also nun nur die konkrete Implementierung eines Algorithmus,
gegeben als \emph{Turingmaschine $tm \in{} TM$} und suchen Aussagen,
die für jeden möglichen ``Input'' auf $tm$ gelten.

Wie können wir nun auf den Ergebnissen aus dem vorherigen Abschnitt aufbauen?
Eine Sprache kann unendlich viele Worte enthalten,
d.h. Lösungen, die darauf beruhen,
dass es ein Minimum oder Maximum von $\tau$ für ein Wort $w \in{} L$ gibt,
sind nicht zielführend.

Wir können aber die \emph{Größe} des Inputs in Relation zum Aufwand setzen,
und so die Implementierung charakterisieren.
Um zu beschreiben,
wie groß der Aufwand für eine Implementierung ist,
suchen wir daher eine Funktion,
welche die Inputgröße auf Anzahl der Schritte abbildet,
die eine Implementierung benötigt,
um das Problem zu lösen.
Übertragen auf den Kontext der formalen Sprachen und Turingmaschinen
können wir die Wortlänge betrachten:
Beschreibe, wie sich das Laufzeitverhalten einer Turingmaschine
bei wachsender Wortlänge verhält.
%TODO Grafik

Gesucht ist also die folgende Funktion:
$t: TM \times \mathbb{N} \rightarrow \mathbb{N}$,
also die Abbildung einer Turingmaschine und einer Wortlänge
auf die Anzahl der Schritte für ein Wort dieser Länge.
Da mehrere Worte die gleiche Länge haben können,
müssen wir die Möglichkeiten diskutieren,
wie wir in diesem Falle zu einem eindeutigen Wert kommen können:
\begin{itemize}
    \item \textbf{Best Case}: Wir wählen das Wort der Länge aus,
        für das der Algorithmus den kürzesten Lauf hat,
        also die geringste Zeit benötigt.
    \item \textbf{Average Case}: Wir nutzen statistische Methoden,
        um den Erwartungswert der Länge eines Laufs zu bestimmen,\footnote{%
            In diesem Fall bildet $tm$ auf $\mathbb{Q}$ ab und nicht mehr auf $\mathbb{N}$.}
        wenn wir per Zufall ein Wort aus $\Sigma^*$ der gegebenen Länge auswählen.\footnote{%
            Der Modus (entspricht dem Median in einer endlichen Stichprobe) wäre eine Alternative.
        Mit der Standardabweichung (Streuungsmaß) oder einer Kombination mehrerer Maße,
        verbessert sich die Aussagekraft,
        was aber die einfache Vergleichbarkeit von Algorithmen wiederum erschwert.}
    \item \textbf{Worst Case}: Wir wählen das Wort aus,
        für das der Algorithmus den längsten Lauf hat,
        also die meiste Zeit benötigt.
\end{itemize}

Da der Best Case meist wenig Aussagekraft über die Güte des Algorithmus besitzt,
wird er selten als Maß für den Aufwand eines Problems genutzt.
Am aussagekräftigsten ist der Average Case,
aber um ihn formal sauber anzuwenden braucht es
entsprechendes statistisches Werkzeug.\footnote{%
    Für interessierte Leser:innen sei~\cite{knuth1}, 96ff bzw. 1.2.10 empfohlen,
    hier spielt Knuth die probabilistische Analyse des Euklidischen Algorithmus durch.}
Ganz pragmatisch konzentrieren wir uns auf Weiteres auf den Worst Case,
wenn wir nichts Anderslautendes angeben.


$t$ können wir mit diesen Überlegungen also definieren als:
\[
t(tm, n) = \max(\{\tau(tm, w)| |w| = n\})
\]
$t$ gibt also die jeweilige Worst Case Laufzeit für ein Wort der Länge $n$ an.
Dies erlaubt es uns auch über unendlich große formale Sprachen Aussagen zu treffen,
indem wir angeben,
wie sich der Aufwand bei steigender Inputgröße,
also bei steigender Wortlänge, entwickelt.

\subsubsection{Blaupause zur Bestimmung von $t$}

\begin{enumerate}
    \item Identifiziere alle Basispfade.\footnote{%
            Basispfade ist die Menge der kürzesten Pfade vom Startzustand in einen Endzustand}
    \item Lege symmetrische Pfade zusammen.\footnote{%
            Symmetrische Pfade sind solche,
            die identisch viele Schritte brauchen und an identische Orte,
            identisch viele Zeichen schreiben.}
    \item Zähle die Schritte der schleifenlosen Basispfade.
    \item Für alle Basispfade, die nicht schleifenlos sind, teile diese auf in:
        \begin{enumerate}
                \item Schleifenlose Teilpfade
                \item Teilpfade mit Einerschleifen
                \item Teilpfade mit komplexen Schleifen.
        \end{enumerate}
    \item Zähle die Schritte der schleifenlosen Teilpfade der Basispfade.
    \item Für die Teilpfade, die nur Einerschleifen\footnote{%
            Einerschleifen sind Schleifen die nur über einen Zustand gehen (Loops in den Grafiken)}
        beinhalten,
        quantifiziere den Aufwand als Funktion, basierend auf einem Restwortmodell.
    \item Für die Teilpfade mit komplexen Schleifen,\footnote{%
            Komplexe Schleifen sind Schleifen, die über mehr als einen Zustand gehen.}
            wende das Verfahren ab Schritt 1
        rekursiv auf die Teilpfade an, mit Startzustand beim Schleifeneingang
        und Endzustand beim Schleifenausgang.
    \item Zähle alle Schritte zusammen, bis alle Basispfade quantifiziert sind.
    \item Identifiziere die Logik, auf welchem Pfad der Worstcase für n liegt.
    \item Gib die Funktion $t$ an.
\end{enumerate}
Dieses Verfahren ist in der Tat nur eine Blaupause,
da wir nicht wissen, ob wir es in einen Algorithmus verwandeln können:
Wir wissen nicht, ob das Verfahren für jede Turingmaschine endet.\footnote{%
    Genaueres über die Gründe werden wir in \autoref{derBarbierUndDerLuegner} erfahren.}

\subsubsection{Beispiel: Aufwand für $tm_{REVERSE}$}


\begin{enumerate}
        \item Für $tm_{REVERSE}$ können wir zwei Basispfade identifizieren:
            \begin{itemize}
                \item $B_1$: Für Worte $w$ mit $|w| = 1$: I $\rightarrow$ C $\rightarrow$ F3.\\
                \item Für Worte $w$ mit $|w| > 1$ gibt es zwei Basispfade:\\
                    \begin{itemize}
                        \item $B_{20}$: I $\rightarrow$ C $\rightarrow$ LS $\rightarrow$ FO $\rightarrow$ OF1 $\rightarrow$ 0F2 $\rightarrow$ F3.\\
                        \item $B_{21}$: I $\rightarrow$ C $\rightarrow$ LS $\rightarrow$ FO $\rightarrow$ 1F1 $\rightarrow$ 1F2 $\rightarrow$ F3.\\
                    \end{itemize}
            \end{itemize}
        \item $B_{20}$ und $B_{21}$ sind symmetrisch und werden als $B_2$ zusammengelegt.
        \item $B_1$ ist schleifenlos. Die Schrittanzahl hier ist 2.
        \item Für $B_2$ ergeben sich drei Teilpfade: von denen der erste Part schleifenlos ist:
            \begin{enumerate}
                \item Der erste Teilpfad $T_1$ ist schleifenlos: I $\rightarrow$ C $\rightarrow$ LS.
                \item Der dritte Teilpfad $T_3$ hat nur Einerschleifen: F0 $\rightarrow \ldots \rightarrow$ F3.
                \item Der zweite Teilpfad $T_2$ hat eine komplexe Schleife: LS $\rightarrow \ldots \rightarrow$ LS.
            \end{enumerate}
        \item Die Schrittanzahl für $T_1$ ist 2.
        \item Die Schrittanzahl für $T_3$ wird mit dem Restwortmodell x(n) ermittelt (siehe \autoref{fig:xwm})
        \item Die Schrittanzahl für $T_2$ wird rekursiv ermittelt (s.u.). Wir definieren dafür den Platzhalter y(n). 
        \item 
            \begin{itemize}
                \item Für $B_1$ ist die Schrittanzahl 2
                \item Für $B_2$ ist die Schrittanzahl 2 + x(n) + y(n)
            \end{itemize}
        \item Die Pfade sind allesamt gleichwertig, daher gilt Worst Case = Best Case.
        \item Daraus ergibt sich die folgende Funktionsdefinition:
\[
    t(n, tm) = \begin{cases}
        2\text{, wenn } x = 1,\\
        2 + x(n) + y(n) \text{, wenn } x > 1,\\
    \end{cases}
\]
\end{enumerate}


\paragraph{Restwortmodell für x(n)}

\begin{figure}[hb]
    \caption{Restwortmodell für $x(n)$}
    \centering
    \begin{tikzpicture}
        \tikzstyle{every path}=[very thick]
        \edef\sizetape{0.7cm}
        \tikzstyle{tmtape}=[draw,minimum size=\sizetape]
        \tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
        arrows={east:.25cm, west:0.25cm}]
        \begin{scope}[start chain=1 going right,node distance=-1.15mm]
            \node [on chain=1,tmtape,draw=none](0) {$\ldots$};
            \node [on chain=1,tmtape] (1) {};
            \node [on chain=1,tmtape] (2) {$c_{1}$};
            \node [on chain=1,tmtape] (3) {$\ldots$};
            \node [on chain=1,tmtape] (4) {$c_{n}$/$o_{1}$};
            \node [on chain=1,tmtape] (5) {$\ldots$};
            \node [on chain=1,tmtape] (6) {$o_n$};
            \node [on chain=1,tmtape, initial above] (7) {};
            \node [on chain=1,tmtape] (8) {};
            \node [on chain=1,tmtape,draw=none] (10) {$\ldots$};
        \end{scope}
        \draw[-|]
            (7.north) edge[bend right=90, above] node{1} (6.north)
            (6.north) edge[bend right=90, above] node{n-1} (4.north)
            (4.north) edge[bend right=90, in=-115, above] node{n-1} (2.north)
            (2) edge[out=75, in=105, looseness=10, above] node{1} (2)
            ;
    \end{tikzpicture}%
    \label{fig:xwm}
\end{figure}
Mit \autoref{fig:xwm} ergibt sich 
\[
    x(n) = 1 + (n-1) + (n-1) +1 = 2n.
\]
\paragraph{Restwortmodell für x(n)}

Da Worte gleicher Länge auch gleich lange Läufe auf $tm_{REVERSE}$ haben
(da, wo sich die Läufe qua Zeichen unterscheiden,
sind die parallelen Pfade in $tm_{REVERSE}$ \emph{symmetrisch}).

            
Für $x(n)$ lässt sich feststellen, dass die Pfade in der Schleife symmetrisch sind.
Anhand von \autoref{fig:x_wm} lässt sich das Restwortmodell so einführen.
$c_i$ mit $2 \leq i < n$ ist der Index, des zu kopierenden Zeichen.
Wir starten auf dem Zeichen rechts von $c_i$ (damit wissen wir,
dass wir danach noch mindestens ein weiteres Zeichen kopieren müssen).
Wir gehen einen Schritt nach links,
dann $(i-1)$ Schritte nach links, bis wir bei $c_1/c^{'}_{n}$ angelangt sind.
Dann weitere $(i-1)$ Schritte nach links, bis wir an dem Punkt sind, an dem
wir $c^{'}_{n-i}$ einsetzen.
Die gleiche Schrittanzahl ($2i -1$) gehen wir wieder zurück und dann noch zwei Schritte.
Daher ergibt sich für jedes zu kopierende Zeichen $i$ die Schrittanzahl $4i - 1$.
Für alle Schritte zusammen (wir wiederholen das ganze n-2 mal) ergibt sich daher:

\begin{figure}[hb]
    \caption{Restwortmodell für $y(n)$}
    \centering
    \begin{tikzpicture}
        \tikzstyle{every path}=[very thick]
        \edef\sizetape{0.7cm}
        \tikzstyle{tmtape}=[draw,minimum size=\sizetape]
        \tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
        arrows={east:.25cm, west:0.25cm}]
        \begin{scope}[start chain=1 going right,node distance=-1.15mm]
            \node [on chain=1,tmtape,draw=none](0) {$\ldots$};
            \node [on chain=1,tmtape] (1) {};
            \node [on chain=1,tmtape] (2) {$c_{i}$};
            \node [on chain=1,tmtape] (3) {$\ldots$};
            \node [on chain=1,tmtape] (4) {$c_{n}$/$o_{1}$};
            \node [on chain=1,tmtape] (5) {$\ldots$};
            \node [on chain=1,tmtape] (6) {$o_i$};
            \node [on chain=1,tmtape, initial above] (7) {$o_{i+1}$};
            \node [on chain=1,tmtape] (8) {?};
            \node [on chain=1,tmtape] (9) {};
            \node [on chain=1,tmtape,draw=none] (10) {$\ldots$};
        \end{scope}
        \draw[-|]
            (7.north) edge[bend right=90, above] node{1} (6.north)
            (6.north) edge[bend right=90, above] node{i-1} (4.north)
            (4.north) edge[bend right=90, above] node{i-1} (2.north)
            (2.south) edge[bend right=90, below] node{i-1} (4.south)
            (4.south) edge[bend right=90, below] node{i-1} (6.south)
            (6.south) edge[bend right=90, below] node{1} (7.south)
            (7.south) edge[bend right=90, below] node{1} (8.south)
            ;
    \end{tikzpicture}%
    \label{fig:ywm}
\end{figure}



\begin{align*}
    x(n) &=&                &   & \sum_{i=2}^{n-1} 4i - 1     &            \\ 
         &=& -(4 - 1)       & + & (\sum_{i=1}^{n} 4i -1)      & - (4n - 1) \\
         &=& -3             & + & -n + 4 (\sum_{i=1}^{n} i)   &  - 4n + 1  \\
         &=& -5n -2         & + & 4 (\frac{n^2+n}{2})         &            \\
         &=& -5n -2         & + & 2 n^2 + 2n                  &            \\
         &=& 2n^2 -3n -2    &   &                             &            
\end{align*}




Daher können wir die finale Definition von $t(n, tm)$ festhalten:
\[
    t(n, tm) = \begin{cases}
        2\text{, wenn } x = 1,\\
        2 n^2 -n \text{, wenn } x > 1,\\
    \end{cases}
\]

Um unsere Definition zu überprüfen, messen wir die Länge der Läufe für  $1 \leq i \leq 5$
(siehe \autoref{tab:ttmreverse}).
Die Funktionsdefinition wird also bestätigt.
\begin{table}[ht]
    \caption{$t(i,tm_{REVERSE})$ für $1 \leq i \leq 5$}
    \centering
    \begin{tabular}{c c c c c c}
    \toprule
          i
        & 1
        & 2
        & 3
        & 4
        & 5
        \\
        \midrule
          $t(i,tm_{REVERSE})$
        & 2
        & 6
        & 15
        & 28
        & 45
        \\
    \bottomrule
    \end{tabular}%
    \label{tab:ttmreverse}
\end{table}


\subsection{Aufwand für ein Problem}
Mit $t_{tm}$ und dem Worst Case-Wert können wir Aussagen über den Aufwand treffen,
den ein bestimmter Algorithmus für ein bestimmtes Problem verursacht.
Wir treffen allerdings keine Aussagen darüber,
wie viel Aufwand das Problem \emph{an sich} erzeugt.
Dazu müssten wir Aussagen über alle prinzipiell \emph{möglichen} Algorithmen,
die das Problem lösen:
Den Aufwand eines Problems würden wir dann mit dem effizientesten Algorithmus gleichsetzen.
Oftmals ist der Nachweis nicht trivial,
ob ein Algorithmus nun der effizienteste für ein Problem gibt

Für REVERSE und Turingmaschinen scheint es keinen Algorithmus zu geben,
der schneller ist, als der in den Beispielen vorgestellte.
Skizzenhaft könnte ein Beweis wie folgt aussehen:
\begin{enumerate}
        \item Wir müssen in jedem Fall jedes Zeichen des Inputworts lesen.
        \item Bis auf ein Zeichen müssen wir jedes an die richtige Stelle verschieben.
        \item Damit müssen wir mindestens $(n-1)$ mal im Durschnitt $2n$ mal
            zwischen Eingabe und Ausgabe hin- und herwechseln.
        \item Daraus folgt, dass jeder Algorithmus mindestens $n^2 - n$ Schritte braucht.
\end{enumerate}

Den aktuellen Stand der Forschung für eine Reihe von relevanten Problemen
(z.B. Sortierung oder Suche) erlernt man in Vorlesungen über
Algorithmen und Datenstrukturen.



\section{Aufwand und Berechnungsmodel}
% Diskussion Modell TM (Einfachheit vs Realitätsnähe)
Skizze:
\begin{itemize}
        \item Revisiting REVERSE:\@ Kontraintuitiver Aufwand bei TMs
        \item Beispiel: Beschleunigung durch 2-Band-Maschine
        \item Simulation weiterer Berechnungsmethoden
        \item Warum doch 1-Band-TMs: Einfachheit
\end{itemize}

Warum nutzen wir (in diesem Skript) Turingmaschinen zur Aufwandsquantifikation?
Wir haben die Church-Turing-These eingeführt und operieren auf der Annahme,
dass sich jedes (berechenbare) Problem durch eine Turingmaschine lösen lässt.

Andere Formalismen lassen sich auf einer Turingmaschine simulieren und
der Aufwand der Simulation lässt sich quantifizieren,
so wir können die ``Beschleunigigung'' durch andere Formalismen
(z.B. solche, die einen realistisches Speicherkonzept haben)
genau beziffern.

\begin{itemize}
    \item Relativ zur Implementierungssprache (Mehrbandturingmaschinen, Registermaschinen)
    \item Relativ zur Datenrepräsentation (Größe des Alphabets, Art der Datenstrukturen)
\end{itemize}

\section{Landau und Big-O:\@ Wachstum}

Eine vergleichbare Analyse für den Algorithmus aus den vorangegangenen Kapiteln,
wird man in den einführenden Lehrbüchern zur theoretischen Informatik
aber auch in denen zu Algorithmen und Datenstrukturen selten finden.
Der Hauptgrund hierfür: Die Analyse ist zu feingranular.
In manchen Grenzfällen in der Praxis kommt es darauf an,
einen Algorithmus zu finden, der die optimale ´'Performance´' hat,
also den geringst-möglichen Aufwand.

Bei der Bewertung von Algorithmen in der theoretischen Informatik,
reicht es aber diese grob in Wachstumsklassen einzuteilen.
Z.B. ist $t(n, tm_{REVERSE}) = 2n^2 - n$ von \emph{quadratischem} Wachstumsverhalten,
das bedeutet, das diese Funktion zur Klasse der \emph{maximal quadratisch wachsenden}
Funktionen gehört.
Dafür schreiben wir auch $t \in O(n^2)$.

Was ist aber mit dem Faktor 2 und $-n$?
Die Motivation diese bei der Klassifikation außer Betracht zu lassen, wird
klar, wenn wir für $n$ sehr große Zahlen einsetzen:
Je größer n, desto kleiner der ´'Beitrag´' von beiden für das Wachstumsverhalten von $t$.
Diese Herangehensweise nennt man auch \emph{asymptotisch}, also annähernd.

Damit können wir die formale Definition der Klasse $O(n^2)$ einführen:
\[
O(n^2) = \{f|\exists c \exists n_0 \forall n (n \geq n_0 \rightarrow f(n) \leq c \cdot n^2)\}
\]

Also eine Funktion gehört zur Klasse der quadratisch wachsenden Funktionen,
wenn das Wachstum der Funktion maximal quadratisch ist,
abgesehen vom Faktor $c$ und ab einem Wert $n_0$.
Zum Beispiel gilt $t \in O(n^2)$, da mit $c=2$ und $n_0 = 0$ gilt: $2n^2 -n \leq 2n^2$.
Die Überlegung wird noch durch \autoref{fig:t_onsq} unterstützt,
die das Wachstumsverhalten der beiden Funktionen grafisch darstellt.

\begin{figure}[h]
    \caption{Plot von $2n^2 - n$ und $n^2$}
    \centering
    \begin{tikzpicture}
      \draw[->] (-2, 0) -- (2, 0) node[right] {$x$};
      \draw[->] (0, -0.5) -- (0, 5) node[above] {$y$};
        \draw[scale=0.5, domain=-2:2, smooth, variable=\x, blue] plot ({\x}, {2*\x*\x - \x}) node[right] {$2n^2 - n$};
        \draw[scale=0.5, domain=-2:2, smooth, variable=\x, red]  plot ({\x}, {2*\x*\x}) node[right]{$2n^2$};
    \end{tikzpicture}%
    \label{fig:t_onsq}
\end{figure}


Das große O (im Englischen: Big-O) ist Teil der Landau-Notation.
Generell können wir Big-O auch allgemein für ein $g(n)$ definieren:

\[
O(g(n)) = \{f|\exists c \exists n_0 \forall n (n \geq n_0 \rightarrow f(n) \leq c \cdot g(n))\}
\]

Die Tabelle \autoref{tab:oklassen} gibt wichtige weitere Klassen an.

\begin{table}[ht]
    \caption{Weitere wichtige Wachstumsklassen}
    \centering
    \begin{tabular}{l l}
        \toprule
        $O(1)$ & konstanter Aufwand \\
        \midrule
        $O(\log n)$ & logarithmisches Aufwands-Wachstum \\
        \midrule
        $O(n)$ & lineares Aufwands-Wachstum \\
        \midrule
        $O(n^2)$ & quadratisches Aufwands-Wachstum \\
        \midrule
        $O(n^k),  k \in \mathbb{N}$ & polynomielles Aufwands-Wachstum \\
        \midrule
        $O(2^n)$ & exponentielles Aufwands-Wachstum \\
    \bottomrule
    \bottomrule
    \end{tabular}%
    \label{tab:oklassen}
\end{table}

% TODO: Ergänze andere Klassen (o, $\theta$ usw).

\subsection*{Aufgaben}

\begin{enumerate}
    \item Gegeben sei die Turingmaschine $tm_{REVERSE2}$ (\autoref{fig:tmreverse2}) für die gilt: $L(tm_{REVERSE}) = L(tm_{REVERSE2})$.
            \begin{enumerate}
                \item Gib Länge $\tau(i, tm_{REVERSE2})$ mit $1 \leq i \leq 5$ an.
                \item Leite analog zu Kapitel x $t(n, tm_{REVERSE2})$ ab.
                \item Gilt $t \in O(t_{a})$?
            \end{enumerate}
\end{enumerate}

\begin{figure}[H] % ’ht’ tells LaTeX to place the figure ’here’ or at the top of the page
\centering % centers the figure
\begin{tikzpicture}
    %Initial part
    \node[state] (zLI) {$z_{LI}$};
    \node[state, left of=zLI] (zI12) {$z_{I12}$};
    \node[state, above of=zLI] (zI02) {$z_{I02}$};
    \node[state, above of=zI12] (zI11) {$z_{I11}$};
    \node[state, above of=zI02] (zI01) {$z_{I01}$};
	\node[state, initial, left of=zI01] (zI) {$z_I$};

    %Loop part
    \node[state, right of=zLI] (zL01) {$z_{L01}$};
    \node[state, above right of=zL01] (zLC) {$z_{LC}$};


    \node[state, below of=zL01] (zL02) {$z_{L02}$};

    \node[state, below right of=zLC] (zL11) {$z_{L11}$};
    \node[state, below of=zL11] (zL12) {$z_{L12}$};

    \node[state, below left of=zL12] (zL3) {$z_{L3}$};

    %Finish part

    \node[state, above left of=zLC] (zF0) {$z_{F0}$};
    \node[state, above right of=zF0] (zF1) {$z_{F1}$};
    \node[state, accepting, right of=zF1] (zF2) {$z_{F2}$};

	\draw

        %Initial part
        (zI) edge[above] node{0,0,L} (zI01)
        (zI01) edge[right] node{$\square$,$\square$,L} (zI02)
        (zI02) edge[left] node{$\square$,0,R} (zLI)

        (zI) edge[above right] node{1,1,L} (zI11)
        (zI11) edge[left, right] node{$\square$,$\square$,L} (zI12)
        (zI12) edge[above] node{$\square$,1,R} (zLI)

        %Loop part
        (zLC) edge[left] node{0,0,L} (zL01)
        (zLC) edge[above right] node{1,1,L} (zL11)
        (zLC) edge[right] node{$\square$,$\square$,L} (zF0)

        (zL01) edge[loop right] node{$\square$,$\square$,L} (zL01)
        (zL01) edge[left]
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (zL02)

        (zL02) edge[loop right]
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (zL02)
        (zL02) edge[right] node{$\square$,0,R} (zL3)

        (zL11) edge[loop right] node{$\square$,$\square$,L} (zL11)
        (zL11) edge[left]
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (zL12)

        (zL12) edge[loop right]
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (zL12)
        (zL12) edge[right] node{$\square$,1,R} (zL3)


        (zL3) edge[loop below]
            node[text width=1cm, align=center]{0,0,R\\1,1,R}
            (zL3)
        (zL3) edge[bend left, left] node{$\square$,$\square$,R}(zLI)

        (zLI) edge[in=210, out=240, looseness=8, below] node{$\square$,$\square$,R} (zLI)
        (zLI) edge[bend left, above left]
            node[text width=1cm, align=center]
            {0,$\square$,R\\1,$\square$,R}
            (zLC)

        %Finish part
        (zF0) edge[loop above] node{$\square$,$\square$,L} (zF0)
        (zF0) edge[below right]
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (zF1)
        (zF1) edge[loop above]
            node[text width=1cm, align=center]{0,0,L\\1,1,L}
            (zF1)
        (zF1) edge[above] node{$\square$,$\square$,R} (zF2)
    ;
\end{tikzpicture}
\caption{$tm_{REVERSE2}$}%
\label{fig:tmreverse2}
\end{figure}

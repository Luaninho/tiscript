\chapter{Einleitung}
\section{Warum theoretische Informatik?}
Warum lohnt sich die Beschäftigung mit theoretischer Informatik?
Die kurze Antwort: Sie liefert einen wesentlichen Teil des Handwerkszeugs,
um die Potentiale und Grenzen der technischen Informationsverarbeitung zu umreißen.
Die lange Antwort soll dieses Skript geben.

Das Skript wurde begleitend zur Veranstaltung ''Theoretische Informatik für Wirtschaftsinformatiker''
an der DHBW Heilbronn erstellt.
Wir folgen in diesem Skript einem kartesischen Ansatz:
Wir gehen vom maximalen Zweifel aus und setzen die theoretische Informatik
als potentiellen Nichtsnutz auf die Anklagebank.
Schritt für Schritt werden wir die Jury (die Studierenden) von der Unschuld dieser
Disiplin überzeugen.
Wir beginnen mit der Feststellung, dass uns als Informatiker:innen die Nützlichkeit
eines Werkzeugs dann einleuchtet, wenn es hilft Probleme zu lösen.
Daher ist der Problembegriff im Mittelpunkt dieses Skripts.

Was also ist ein Problem?
Bevor wir diese Frage grundlegend beantworten können,
ist es hilfreich ein paar Probleme kennen zu lernen,
wie sie im IT-Alltag auftreten können.

\section{Probleme}
Wir werden nun ein paar alltägliche Probleme als Userstories wiedergeben.
Eine Userstory wird in der agilen Softwareentwicklung genutzt um Anforderungen zu spezfizieren.
Es folgt typischerweise diesem Format:
''Als \textless Rolle\textgreater\ möchte ich \textless Feature\textgreater,
um \textless Ziel\textgreater\ zu erreichen.''

\begin{itemize}
    \item \textbf{MAX}: Als Filialleiterin möchte ich das beste Produkt kennen,
        um meine Lieferungen zu optimieren.
    \item \textbf{MATCH}: Als Einkaufsmanager möchte ich,
        dass nur valide Lieferanten-IDs gespeichert werden,
        um Fehler in der Datenbank zu vermeiden.
    \item \textbf{HALT}: Als Product Owner des Serverless-Computings möchte ich,
        dass nur terminierende Code-Snippets deployt werden,
        um die verfügbaren Ressourcen effizient zu nutzen.
    \item \textbf{ROUTE}: Als Kommissioniererin möchte ich,
        dass morgens die optimalen Routen für die LKWs in die 24 Filialen berechnet werden,
        um die Lieferzeit zu minimieren.
    \item \textbf{QUANTUMSEC}: Als Chief Security Officer möchte ich,
        dass die firmen-interne Kommunikation quantensicher verschlüsselt wird,
        um die Vertraulichkeit der Absprachen zu garantieren.
\end{itemize}

Alle Probleme treten in einer Form auf,
wie sie viele IT-Angestellten täglich vorfinden, dann analysieren und schließlich lösen müssen.
Die theoretische Informatik kann auch einiges über diese Probleme sagen:
\begin{itemize}
    \item Mindestens ein Problem ist sehr schwer zu lösen.
    \item Mindestens ein Problem ist sehr einfach zu lösen.
    \item Mindestens ein Problem ist nicht lösbar.
    \item Bei mindestens einem Problem ist unklar, ob es sich lösen lässt.
\end{itemize}

Am Ende dieses Skriptes soll klar sein, welches dieser Probleme in welche dieser Kategorien fällt.
An diesem Punkt im Text wollen wir uns aber zunächst damit begnügen,
dass ein Fach Nutzen bringt, dass es erlaubt, diese Probleme auf einen Blick als leicht oder
schwer, unlösbar oder von unbekannter Komplexität zu kategorisieren.

\section{Abstraktion}

Um die Probleme aus dem vorigen Absatz für die Bearbeitung mit den Werkzeugen der
theoretischen Informatik vorzubereiten ist noch etwas an Arbeit notwendig.
Ein grundlegendes Instrument der Informatik (nicht nur der theoretischen) 
ist die \emph{Abstraktion}, also die ausschließliche Betrachtung der Aspekte eines Sachverhalts,
die für die Lösung eines Problems wesentlich sind.

Schritt für Schritt kann man die unwesentlichen Aspekte abstreifen,
bis man zum Kern des Problems vorgedrungen ist,
wie wir exemplarisch am \textbf{MAX}-Problem demonstrieren:

\begin{enumerate}
    \item Wer das beste Produkt aus welchem Grund kennen will,
    scheint für die algorithmische Betrachtung gleichgültig.
    \item Ob es das beste Produkt im Sinne der Verkaufshäufigkeit oder der Gewinnmarge ist,
    erscheint ebenfalls unwesentlich.
    \item Es sollte auch unwesentlich sein, ob wir ein Liste von Produkten,
    oder andere Objekte durchsuchen; wesentlich ist,
    dass wir in einer Dimension das Maximum suchen.
\end{enumerate}

Am Ende des Prozesses kommen wir auf den Kern des \textbf{MAX}-Problems:
\begin{itemize}
    \item \textbf{Gegeben:} Eine n-stelliger Tupel von Zahlen
    \item \textbf{Gesucht:} Die größte Zahl aus dem Tupel 
\end{itemize}

Es gibt keinen einfachen und eindeutigen Weg von einer Userstory
zu einem abstrakten Problem zu kommen.
Aber jede der möglichen Abstraktionen wird letztlich in dieser Form resultieren:
\begin{itemize}
    \item \textbf{Gegeben:} Ein (potentiell komplexer) Eingabewert
    \item \textbf{Gesucht:} Ein (potentiell komplexer) Ausgabewert
\end{itemize}
Diese Form der Problemangabe wollen wir ''informell'' nennen.

Es ist durchaus möglich,
dass wir die falschen Dimensionen für den Anwendungsfall wegabstrahieren.
Wie man dies verhindern kann, lehrt die Disziplin des Software Engineerings.
Für unsere Betrachtung wollen wir aber davon ausgehen,
dass das Finden des Maximums aus einer Menge an Zahlen
- sagen wir der Einfachheit halber der natürlichen Zahlen -
exakt der Kern des \textbf{MAX}-Problems ist.

Wenn wir das Problem in der Form ``Gegeben/Gesucht'' angeben, entspricht es einer Funktion:
$f_{MAX}: \mathcal{P}(\mathbb{N}) \rightarrow \mathbb{N}$.
Aus einer (endlichen) Teilmenge der natürlichen Zahlen wollen wir die Zahl,
die größer ist, als alle anderen Zahlen.\footnote{

dass 








In diesem Sinne können wir das Problem darstellen,
indem wir alle Eingabe- und Ausgabewerte so aufzählen,
dass die Ausgabewerte eine ``Lösung'' für die Eingabewerte sind.
Da die Reihenfolge für die gegebenen Werte irrelevant sind,
können wir sie als Menge darstellen.



Für \textbf{MAX} hieße das z.B.:
\begin{itemize}
    \item Eingabe: $\{0, 1\} \rightarrow 1$
    \item Eingabe: $\{0, 2\} \rightarrow 2$
    \item ... 
    \item Eingabe: $\{0, 1, 2, 3\} \rightarrow 3$
    \item ... 
\end{itemize}
Wir halten fest, dass die Abstraktion ein Werkzeug ist,
Probleme auf ihren Kern zu reduzieren.
Diese abstrakte, informelle Form des Problems hat genau den Umfang,
der so klein wie möglich und so groß wie nötig ist.

Allerdings haben wir das \textbf{MAX}-Problem noch nicht in der Form angegeben,
die nötig ist, um es mit den Werkzeugen der theoretischen Informatik zu bearbeiten.
Software-Entwickler:innen wären mit unserem Zwischenergebnis vielleicht schon zufrieden,
denn sie wüssten, wie man ein informelles Problem
in der präferierten Programmiersprache lösen kann.
Welche Form die theoretische Informatik verlangt, soll im nächsten Abschnitt diskutiert werden.

\section{Formalisierung}

Die Informatik ist die Wissenschaft der maschinellen Informationsverarbeitung,
daher ist es sinnvoll zu überlegen,
wie Informationen Input für eine bzw. Output von einer Maschine sein können.
Ein einfaches Modell ist die Tastatur und der Bildschirm:
Eine endliche Menge von Zeichen (die Knöpfe der Tastatur) werden übersetzt in eine
endliche Menge von Zeichen (die Pixel eines Bildschirms).
Tatsächlich werden die meisten Informationen,
die eine Maschine oder ein Computer verarbeiten,
maschinen-intern in eine sehr kleine Menge an Zeichen übersetzt:
in Zeichenfolgen bestehend aus Nullen und Einsen.

Wir kodieren also Zahlen, Videos, Bilder, Musik, Texte, im Allgemeinen alle Datenstrukturen
und Ausgabewerte als Folgen von Nullen und Einsen,
also als binäre Zeichenfolgen.
Ebenso werden Anweisungen, was mit diesen binären Daten passieren soll,
als binäre Zeichenfolgen kodiert.
Ganz allgemein könnte man also sagen, dass alle Probleme, die ein Computer lösen soll,
sich in diese Form bringen lassen:
\begin{itemize}
    \item \textbf{Gegeben:} Eine binäre Zeichenfolge.
    \item \textbf{Gesucht:} Eine binäre Zeichenfolge.
\end{itemize}

Wie lässt sich nun aber eine Zeichenfunktion so darstellen,
dass unsere Probleme adäquat repräsentiert sind?
Damit wir dies erreichen,
müssen wir zunächst noch einige Begriffe definieren und Konventionen einführen.

\subsection{Zeichen}

Eine Menge von Zeichen bezeichnen wir als \emph{Alphabet}, kurz: $\Sigma$.
Z.B.: $\Sigma = \{0,1\}$.\\

\noindent
Wir verwenden diese Variablen für Zeichen: $a,b,c$;
wenn wir diese Buchstaben verwenden und nichts anderes angeben,
gilt implizit: $a, b, c \in \Sigma$ für ein gegebenes $\Sigma$.\footnote{
Wenn $\Sigma$ nicht explizit angegeben oder aus dem Kontext herleitbar ist,
wird $\Sigma$ also auch als Variable für (irgend) ein Alphabet verwendet.}\\

\noindent
Eine Operation auf den Zeichen ist die \emph{Konkatenation},
also die Verbindung von zwei Zeichen, z.B. $01$.
Wie bei der Multiplikation mit Variablen in der Mathematik üblich,
wird die Konketanation nicht explizit mit einem eigenen Zeichen repräsentiert,
dennoch ist sie formal eine Operation.

\subsection{Worte}
Das Ergebnis einer beliebig oft ausgeführten Konkatenation,
also eine (binäre) Zeichenfolge,
bezeichnen wir als \emph{Wort}, z.B.: $0101010001001001$\\

\noindent
Die Menge aller Wörter,
die sich aus einem Alphabet bilden lassen,
bezeichnen wir als \emph{Kleensche Hülle}, dargestellt als Stern: $\Sigma^*$.\\

\noindent
Wir verwenden diese Variablen für Worte:
$w, x, y, z$; wenn wir diese Buchstaben verwenden und nichts anderes angeben,
gilt implizit: $w, x, y, z \in \Sigma^*$.\\

\noindent
Die \emph{Länge} eines Wortes ist die Anzahl seiner Zeichen.
Formal benutzen wir die Betragsstriche um ein Wort, um seine
Länge zu bezeichnen. Wenn z.B. $w = 0101010001001001$, dann gilt $|w| = 16$.\\

\noindent
Das Wort mit der Länge 0, also das Wort, dass aus null Zeichen besteht,
nennen wir das \emph{leere Wort}, kurz: $\epsilon$.
Es gilt $|\epsilon| = 0$.\\

\noindent
Für die n-malige Wiederholung eines Zeichens oder Wortes führen wir den \emph{Wiederholungsoperator}
ein, eine hochgestellte Zahl $n \in \mathbb{N}$: $a^n$ oder $w^n$.
Z.B. $0^3 = 000$ und $(10)^2 = 1010$.
$a^0$ bzw. $w^0$ entspricht dabei $\epsilon$.\\

\noindent
Wollen wir ein angeben, dass ein Zeichen oder Wort beliebig oft (also auch 0-mal) wiederholt
wird, nutzen wir dafür einen hochgestellten Stern, den \emph{Kleene-Operator} $a^*$ oder $w^*$.
Mit dem Kleene-Operator bezeichnen wir immer eine unendliche Menge von Wörtern, z.B.:
$a^* = \{\epsilon, a, aa, aaa, aaaa, \dots\}$

\subsection{Formale Sprachen}

Nachdem wir von Zeichen und Worten gesprochen haben, liegt die Frage nahe,
ob man denn auch von Sprachen sprechen kann und tatsächlich ist die formale Sprache 
ein zentraler Begriff der theoretischen Informatik.
Bevor wir den Begriff der formalen Sprachen einführen, ist noch eine Warnung angebracht:
Während die Verwendung des Begriffs ''Zeichens''
noch recht intuitiv mit dem Begriff des Buchstaben zusammenfällt
(zumindest im deutschsprachigen Raum),
ist schon der formal eingeführte Wort-Begriff eher eine Zumutung für unsere Intuition:
Worte im Sinne des vorangegangenen Abschnitts sind einfach irgendwelche Zeichenfolgen,
egal ob sie aussprechbar oder im Kontext einer natürlichen Sprache
(wie deutsch oder englisch) einen Sinn ergeben.

Man müsste also eigentlich das natursprachliche $Wort_N$ von dem formalen $Wort_F$ trennen,
das wir oben eingeführt haben.
Eine Crux aller formal arbeitenden Wissenschaften ist,
dass die Menge an Zeichen und Begriffen begrenzt ist und daher Doppeldeutigkeiten auftreten.
Im Kontext dieses Skriptes ist ein Wort meist im formalen Sinne gemeint.
Sollte dies nicht der Fall sein und der Kontext nicht ausreichen,
um zwischen beiden Bedeutungen zu unterscheiden,
werden wir die subskribierten Varianten verwenden.

Die vorige Überlegung trifft nicht nur auf Worte, sondern auch auf \emph{Sprachen} zu.
Eine Sprache im Sinne der theoretischen Informatik ist einfach eine Menge von Worten.
Z.B. ist $L = \{0, 1, 00, 01, 10, 11 \}$ die Sprache der Worte,
die aus einem oder zwei Binärzeichen bestehen.
Wesentlich ist eine formale Sprache als \emph{Menge} im Sinne der Mengenlehre aufzufassen, 
nicht als Kommunikationsmedium mit einer eigenen Sprachgeschichte und Sprachgemeinschaft.\\

\noindent
Wir verwenden $L$ (ggf. mit unterschiedlichen Subskripten) als Variable für Sprachen;
wenn wir $L$ verwenden und nichts Anderslautendes angeben ist,
gilt implizit $L \subseteq \Sigma^*$ für ein gegebenes $\Sigma$.\\

\noindent
Da Sprachen Mengen sind,
sind alle mengentheoretischen Operationen\footnote{siehe \autoref{mengenlehre}}
auf Sprachen definiert,
z.B. $L_1 \cap L_2 = \{w | w \in L_1 \wedge w \in L_2\}$
bezeichnet die Schnittmenge zweier Sprachen, also alle Wörter,
die sowohl Element von $L_1$ als auch von $L_2$ sind.

\subsection{Probleme als Sprachen}
Mit den oben eingeführten Begriffen können
wir nun ein Problem im Sinne der theoretischen Informatik
\emph{formalisiert} einführen.
Die grundlegende Idee dabei: Ein Problem lässt sich durch eine formale Sprache repräsentieren,
d.h. wir finden zu einem Problem eine Sprache, die der folgenden bekannten informellen
Darstellung entspricht:
\begin{itemize}
    \item \textbf{Gegeben:} Eine binäre Zeichenfolge. 
    \item \textbf{Gesucht:} Eine binäre Zeichenfolge.
\end{itemize}
Um nun ein Problem wie \textbf{MAX} als binäre Zeichenfolge darstellen zu können,
müssen wir zunächst eine Binärkodierung für Zahlen finden:
$Bin_{LE}: \mathbb{N} \rightarrow \{0,1\}$
Die Little Endian Dual-Kodierung erfüllt diese Anforderung,
also die Repräsentation von natürlichen Zahlen bei der
das niedrigstwertige Bit am Anfang steht.
Zum Beispiel ist $Bin_{LE}(6) = 011$, mit 
$
0 \cdot 2^0
+ 1 \cdot 2^1
+ 1 \cdot 2^2
= 6
$.\footnote{TODO: Füge Ressource hinzu, die Dual-Kodierung und LE/BE erklärt;
entweder als Referenz oder in Kapitel 1}

Damit wir nun nicht nur einfache Zahlen, sondern auch Zahlenfolgen kodieren können,
müssen wir noch eine weitere Kodierung einführen,
die es erlaubt an einer binärem Wort zu erkennen,
wo eine Zahl anfängt und die nächste beginnt.
Dies kann mit der folgenden Kodierung erreicht werden: 
$Bin_{SET}:$ 







\section{Weitere Werkzeuge der theoretischen Informatik}

\section{Drei grundlegende Fragen}
Zusammen mit dem Begriff eines Problems und seiner Formalisierung ist also der
\emph{Berechenbarkeitsbegriff} im Herzen dieses Skriptes.
Wir hätten auch andere Begriff auswählen können, um in die Ideen der theoretischen Informatik einzuführen:
Formale Sprachen, Automaten, Information, Aufwand, Überprüfbarkeit wären solche Kandidaten gewesen.
Das Problem und die Berechenbarkeit erlauben uns aber eine ganz Praxis-nahe Einführung.
Die anderen Begriffe werden wir in diesem Skript streifen, aber nicht in den Fokus setzen.

Mit unseren beiden Kernbegriffen können wir die drei Grundfragen dieses Skriptes stellen:
\begin{enumerate}
    \item Was lässt sich effizient berechnen?
    \item Was lässt sich überhaupt berechnen?
    \item Welche Rolle spielt die Formalisierung der Berechenbarkeit für die zwei ersten Fragen?
\end{enumerate}

Diese drei Fragen korrespondieren zu drei Grunddisziplinen der theoretischen Informatik:
\begin{enumerate}
    \item Komplexitätstheorie
    \item Berechenbarkeitstheorie
    \item Theorie der formalen Sprachen und der Automaten
\end{enumerate}

Im Rest des Skriptes werden wir die drei Fragen bearbeiten und
dabei die drei Grunddsiziplinen und ihre Fragestellungen, Ergebnisse und Methodiken kennenlernen.
Wir haben diese Probleme in zwei Schritten erst abstrahiert und dann kodiert:
\begin{enumerate}
    \item \emph{Abstraktion:}
        \\\textbf{Gegeben:} Eine Datenstruktur
        \\\textbf{Gesucht:} Ein Ausgabewert
    \item \emph{Kodierung:}
        \\\textbf{Gegeben:} Eine Zeichenfolge, die eine Datenstruktur kodiert.
        \\\textbf{Gesucht:} Eine Zeichenfolge, die einen Ausgabewert kodiert.
\end{enumerate}
Der letzte Schritt ist nun das gesamte Gegeben/Gesucht-Paar
als Menge von Worten zu \emph{formalisieren},
was wir am Beispiel von \textbf{MAX} zeigen wollen:
\begin{enumerate}
    \item \emph{Abstraktion:}
        \\\textbf{Gegeben:} Eine Liste von Zahlen, z.B.: $\{1,2,3,4\}$
        \\\textbf{Gesucht:} Die größte Zahl der Liste, z.B. $4$.
    \item \emph{Kodierung:}
        \\\textbf{Gegeben:} Eine binäre Kodierung einer Menge von Zahlen, z.B.:
        \\$\{001, 010, 011, 100\}$
        \\\textbf{Gesucht:} Eine binäre Kodierung der größten Zahl aus der Menge, z.B.:
        \\$100$
\end{enumerate}

Formal können wir \textbf{MAX} also als eine ''Auswahl-Funktion'' aus einer Menge begreifen,
sodass gerade das Element ausgewählt wird, dass am größten ist.
Eine Funktion $f: D \rightarrow W$ lässt sich mengentheoretisch als Menge von Tupeln auffassen,
so dass gilt $f = \{[d,w]|d \in D \wedge w \in W\}$.

\noindent
Für unser Beispiel von oben gilt dann also
\begin{itemize}
    \item $[\{1,2,3,4\},4] \in \bf{MAX}$, bzw.:
    \item $[\{001, 010, 011, 100\}, 100] \in \bf{MAX}$
\end{itemize}

Der letzte Schritt ist nun, die \emph{gesamte} Funktion zu formalisieren, also eine Kodierung
für \textbf{MAX} anzugeben.
Dazu müssen wir eine binäre Kodierung von Tupeln von Binärdaten einführen.
Eine simple Variante wäre die folgende Kodierung:

\section{Weitere Werkzeuge der theoretischen Informatik}

\section{Drei grundlegende Fragen}
Zusammen mit dem Begriff eines Problems und seiner Formalisierung ist also der
\emph{Berechenbarkeitsbegriff} im Herzen dieses Skriptes.
Wir hätten auch andere Begriff auswählen können, um in die Ideen der theoretischen Informatik einzuführen:
Formale Sprachen, Automaten, Information, Aufwand, Überprüfbarkeit wären solche Kandidaten gewesen.
Das Problem und die Berechenbarkeit erlauben uns aber eine ganz Praxis-nahe Einführung.
Die anderen Begriffe werden wir in diesem Skript streifen, aber nicht in den Fokus setzen.

Mit unseren beiden Kernbegriffen können wir die drei Grundfragen dieses Skriptes stellen:
\begin{enumerate}
    \item Was lässt sich effizient berechnen?
    \item Was lässt sich überhaupt berechnen?
    \item Welche Rolle spielt die Formalisierung der Berechenbarkeit für die zwei ersten Fragen?
\end{enumerate}

Diese drei Fragen korrespondieren zu drei Grunddisziplinen der theoretischen Informatik:
\begin{enumerate}
    \item Komplexitätstheorie
    \item Berechenbarkeitstheorie
    \item Theorie der formalen Sprachen und der Automaten
\end{enumerate}

Im Rest des Skriptes werden wir die drei Fragen bearbeiten und
dabei die drei Grunddsiziplinen und ihre Fragestellungen, Ergebnisse und Methodiken kennenlernen.
